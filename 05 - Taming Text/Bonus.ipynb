{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we want to gather the sender and receiver of all emails.\n",
    "\n",
    "Let's start by loading the email file. We only need the EmailId and the SenderPersonId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emails = pd.read_csv('hillary-clinton-emails/Emails.csv', usecols=['Id', 'SenderPersonId'])\n",
    "emails.rename(columns={'Id':'EmailId'}, inplace=True)\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the receivers of the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "receivers = pd.read_csv('hillary-clinton-emails/EmailReceivers.csv', index_col=0)\n",
    "receivers.rename(columns={'PersonId':'ReceiverPersonId'}, inplace=True)\n",
    "receivers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we loaded both files, we can join them on the EmailId to get the sender and the receiver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.merge(receivers, emails, on='EmailId').dropna()\n",
    "\n",
    "print(len(data))\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edges = data[['ReceiverPersonId', 'SenderPersonId']]\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = nx.from_pandas_dataframe(edges, 'ReceiverPersonId', 'SenderPersonId')\n",
    "# We use the degree of the nodes to set their size\n",
    "d = nx.degree(G)\n",
    "node_size = [(v + 2) * 8 for v in d.values()]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 13))\n",
    "nx.draw(G, nodelist=d.keys(), node_size=node_size, width=0.5, node_color='#2b8ceb', alpha=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communities\n",
    "Now we want to see if there are communities in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import community\n",
    "part = community.best_partition(G)\n",
    "values = [part.get(node) for node in G.nodes()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the graph using the computed communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 13))\n",
    "\n",
    "\n",
    "nx.draw_spring(G, cmap=plt.get_cmap('Set1'), node_color = values, node_size=node_size, alpha=0.8, width=0.5, with_labels=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 words by communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We create a dataframe from the communities computed above.\n",
    "groups = pd.DataFrame.from_dict(part, orient='index')\n",
    "groups = groups.reset_index()\n",
    "groups.rename(columns={0: 'group', 'index': 'PersonId'}, inplace=True)\n",
    "groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emails = pd.read_csv('hillary-clinton-emails/Emails.csv', usecols=['Id', 'SenderPersonId', 'RawText']).dropna()\n",
    "emails.rename(columns={'SenderPersonId': 'PersonId'}, inplace=True)\n",
    "data = pd.merge(emails, groups, on='PersonId').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_emails = data.groupby('group').apply(lambda x: \"%s\" % ' '.join(x['RawText']).replace('\\n', ' ')).to_frame()\n",
    "grouped_emails.rename(columns={0: 'emails'}, inplace=True)\n",
    "grouped_emails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def word_count(txt, n):\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    word_list = txt.split()\n",
    "    count = {}\n",
    "    for word in word_list:\n",
    "        if word not in stop_words:\n",
    "            if word in count:\n",
    "                count[word] = count[word] + 1\n",
    "            else:\n",
    "                count[word] = 0\n",
    "    return sorted(count, key=count.get, reverse=True)[:n]\n",
    "\n",
    "        \n",
    "grouped_emails['top_words'] = grouped_emails['emails'].apply(lambda emails: word_count(emails, 20))\n",
    "grouped_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
