{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd             \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt   \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats.mstats import mode\n",
    "from sklearn import preprocessing\n",
    "#from sklearn import model_selection\n",
    "from sklearn.preprocessing import Imputer\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will do some data preprocessing to make the dataset reading for training. Indeed by reading through the example notebook and by further analysis. Some inconsitencies will be problematic durint the training of the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('CrowdstormingDataJuly1st.csv', index_col=0)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to remove all the rows from which we can not infere the answer to the question asked. We need to find the skin color of the soccer player based on the other feature at our disposal. We will thus first take interest in the column '_rater1_' and '_rater2_'. By looking at the dataset we can directly see that some rows have no \"rating\" and won't be able to help use during the training: we don't have the output labels for the classifier. This is only a real problem when using supervised learning.\n",
    "\n",
    "We only have rating for ~85% of the dataset also each sample is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Good news we always have either the two rating or none\n",
    "sum(~(df.rater1.isnull() == df.rater2.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = df.dropna(subset=['rater1', 'rater2']).copy()\n",
    "print('Total available', len(df))\n",
    "print('Total with rating', len(data), \"({}%)\".format(round(len(data)*100/len(df),3)))\n",
    "print('Number of sample with disagrement:', sum(~(data.rater1 == data.rater2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['skin'] = data[['rater1', 'rater2']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at own many \"real\" unique sample we have. Indeed a player is most certainly present multiple times. As we can see most of the players have several entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of unique player\", len(data.player.unique()))\n",
    "fig, ax = plt.subplots();\n",
    "plt.plot(data.player.value_counts().tolist())\n",
    "ax.set_title('Apparition count per player')\n",
    "ax.set_xlabel('Player')\n",
    "ax.set_ylabel('Apparition Count')\n",
    "#data.player.value_counts().tolist().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will aggregate the data to only work with a sample per player. Some of the player are present only one time and other more than one hundred time.\n",
    "\n",
    "Also a classifier as no notions of strings as input we thus need to deal with the columns with text features and encode them in a different way. We could either use a numbering encoding (clubX = 1, clubY = 2, etc) or juste dummy encode the column. We will use the dummy encoding.\n",
    "\n",
    "We also deal with the missing data (_nan_ values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill Nan values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the missing values. We will have to deal with all of them before feeding anything to the classifier. As we can see some of the column have several missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Height & Weight : Use mean\n",
    "data['height'] = data['height'].fillna(data['height'].mean())\n",
    "data['weight'] = data['weight'].fillna(data['weight'].mean())\n",
    "\n",
    "# Position: add mew label\n",
    "data['position'] = data['position'].fillna('UNKNOWN')\n",
    "\n",
    "# We decided to drop all rows containging nan in the rest of the columns. Indeed it would be difficult to \n",
    "# decide by which value we need to fill the data as they are specific for each dyad player - referee\n",
    "data.dropna(subset=['Alpha_3', 'meanIAT', 'nIAT','seIAT','meanExp','nExp','seExp'],axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to work only with information about player not dyad player-referee. We need to aggregate the unformation about each player into a single sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO Add age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_present = lambda x: x.value_counts().index[0]\n",
    "\n",
    "players = data.groupby(level=0).agg({\n",
    "    'leagueCountry': most_present,\n",
    "    'position': most_present,\n",
    "    'height': 'mean', \n",
    "    'weight': 'mean', \n",
    "\n",
    "    'meanIAT':'mean', \n",
    "    'meanExp':'mean', \n",
    "    'seIAT':'mean', \n",
    "    'seExp':'mean',\n",
    "\n",
    "    'games':'sum', \n",
    "\n",
    "    'victories':'sum',\n",
    "    'defeats':'sum', \n",
    "    'ties': 'sum', \n",
    "\n",
    "    'goals':'sum', \n",
    "\n",
    "    'redCards':'sum', \n",
    "    'yellowReds': 'sum', \n",
    "    'yellowCards':'sum',\n",
    "\n",
    "    'skin': most_present,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simplification of the task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is all its glory is to determine the skin color within the same 5 categories. Because there is some deisagrement between raters. New \"categories\" have been created that lie in between the official ones. Let's look at the distribution of those categories. As we can see below, the categories are skewed to the right (to the \"white\" side of the categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = players['skin'].value_counts(sort=False).sort_index().plot(kind='bar')\n",
    "fig.set_ylabel('Number of players')\n",
    "fig.set_xlabel('Skin \"category\"')\n",
    "fig.set_title('Skin category by players')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to reframe the problem to a classification that decide if the playe has light skin or dark skin. Even though we will first try a simple model on the determination of the whole range of skin categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players['skin_binary'] = pd.cut(players['skin'], [0, 0.5, 1.01], labels=['light', 'dark'], right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will thus work on classifing into two category with the following distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = players['skin_binary'].value_counts(sort=False).plot(kind='bar')\n",
    "fig.set_ylabel('Number of players')\n",
    "fig.set_xlabel('Skin \"category\"')\n",
    "fig.set_title('Skin category by players')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models can not work on text features such as the position and such. We will dummy encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = players.copy()\n",
    "X.drop(['skin', 'skin_binary' ], axis=1, inplace=True)\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "y_full = players.copy()['skin']\n",
    "y = players.copy()['skin_binary']\n",
    "\n",
    "# Just create a struct like object\n",
    "dataset = lambda:0\n",
    "dataset.X = X\n",
    "dataset.y_full = y_full\n",
    "dataset.y = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our dataset into train and test. The model will be \"definied/trained\" using the train dataset and the model will be comprared on the classification based on the test set. We don't look at the test set until we do the comparision between different model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, dataset.y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will define our baseline. We start by selecting randomly the skin color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_random = np.random.randint(2, size=y_test.shape)\n",
    "accuracy_score(y_test, y_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve the score just by selecting the most present skin color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_present = mode(y_train)[0][0] # Model is definied based on train set\n",
    "y_most = np.full(y_test.shape, most_present, dtype=int)\n",
    "accuracy_score(y_test, y_most)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to developpe un classifier that will improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_estimators = 30\n",
    "max_depth = 20\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=20, max_features=None)\n",
    "scores_cross_val = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "scores_test = accuracy_score(y_test, clf.predict(X_test))\n",
    "\n",
    "print(\"Cross validation score:\", np.mean(scores_cross_val))\n",
    "print(\"Test set validation score:\", scores_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that just going straight to the goal without much thinking is not going to work. We obtain just a bit of gain compared to selecting the most present class. Let's see where we are on the overfitting side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_train, clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well... We overfit _quiet_ a bit."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
