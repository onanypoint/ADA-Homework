{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd             \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt   \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats.mstats import mode\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will do some data preprocessing to make the dataset readable for training. Indeed by reading through the example notebook and by further analysis. Some inconsitencies will be problematic furing the training of the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('CrowdstormingDataJuly1st.csv', index_col=0)\n",
    "df['rater1'] = df['rater1'].astype('category')\n",
    "df['rater2'] = df['rater2'].astype('category')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to remove all the rows from which we can not infere the answer to the question asked. We need to find the skin color of the soccer player based on the other feature at our disposal. We will thus first take interest in the column '_rater1_' and '_rater2_'. By looking at the dataset we can directly see that some rows have no \"rating\" and won't be able to help use during the training: we don't have the output labels for the classifier.\n",
    "\n",
    "We only have rating for ~85% of the dataset also each sample is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Good news we always have either the two rating or none\n",
    "sum(~(df.rater1.isnull() == df.rater2.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = df[~df.rater1.isnull()].copy()\n",
    "print('Total available', len(df))\n",
    "print('Total with rating', len(data), \"({}%)\".format(round(len(data)*100/len(df),3)))\n",
    "print('Number of sample with disagrement:', sum(~(data.rater1 == data.rater2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at own many \"real\" unique sample we have. Indeed a player is most certainly present multiple times. As we can see most of the players have several entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of unique player\", len(data.player.unique()))\n",
    "rows_per_player = data.player.value_counts()\n",
    "rows_per_player.hist(bins=28, range=(0, 280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will aggregate the data to only work with sample per player. Some of the player are present only one time and other more than one hundred time. Feeding the samples right away would not be a good thing. The data is skewed and thus the model won't be able to learn correctly to classify unseen data that might be closer to a player present only once.\n",
    "\n",
    "We will deal with the missing data (_nan_ values) directly in the model declaration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data.groupby(level=0).agg({\n",
    "        'leagueCountry': 'first',\n",
    "        'position':'first',\n",
    "        'height':'first', \n",
    "        'weight':'first', \n",
    "        'games':'sum', \n",
    "        'victories':'sum',\n",
    "        'defeats':'sum', \n",
    "        'ties': 'sum', \n",
    "        'goals':'sum', \n",
    "        'redCards':'sum', \n",
    "        'yellowReds': 'sum', \n",
    "        'yellowCards':'sum'\n",
    "    })\n",
    "\n",
    "# Just create a struct like object\n",
    "dataset_raw = lambda:0\n",
    "dataset_raw.X = pd.get_dummies(X)\n",
    "dataset_raw.y = data.groupby(level=0)['rater1'].apply(lambda x: mode(x, axis=None)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skin_color = preprocessing.LabelEncoder()\n",
    "\n",
    "dataset = lambda:0\n",
    "dataset.X = dataset_raw.X.as_matrix()\n",
    "dataset.y = skin_color.fit_transform(dataset_raw.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our dataset into train and test. The model will be \"definied\" using the train dataset and the model will be comprared on the classification based on the test set. We don't look at the test set until we do the comparision between different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imputer = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imputer = imputer.fit(dataset.X)\n",
    "X = imputer.transform(dataset.X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, dataset.y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will define our baseline. We start we selecting randomly the skin color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_random = np.random.randint(5, size=y_test.shape)\n",
    "accuracy_score(y_test, y_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve the score just by selecting the most present skin color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_present = mode(y_train)[0][0] # Model is definied based on train set\n",
    "y_most = np.full(y_test.shape, most_present, dtype=int)\n",
    "accuracy_score(y_test, y_most)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to developpe a classifier that will improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_estimators = 30\n",
    "max_depth = 20\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that just going straight to the goal without much thinking is not going to work. We obtain just a bit of gain compared to selecting the most present class. Let's see where we are on the overfitting side, and test the accurary of our classifier on the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_train, clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well... We overfit _quiet_ a bit."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
