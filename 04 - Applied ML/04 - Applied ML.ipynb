{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd             \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt   \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats.mstats import mode\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will do some data preprocessing to make the dataset ready for training. Indeed by reading through the example notebook and by further analysis. Some inconsitencies will be problematic durint the training of the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('CrowdstormingDataJuly1st.csv', index_col=0)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to remove all the rows from which we can not infere the answer to the question asked. We need to find the skin color of the soccer player based on the other feature at our disposal. We will thus first take interest in the column '_rater1_' and '_rater2_'. By looking at the dataset we can directly see that some rows have no \"rating\" and won't be able to help use during the training: we don't have the output labels for the classifier. This is only a real problem when using supervised learning.\n",
    "\n",
    "We only have rating for ~85% of the dataset also each sample is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Good news we always have either the two rating or none\n",
    "sum(~(df.rater1.isnull() == df.rater2.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = df.dropna(subset=['rater1', 'rater2']).copy()\n",
    "print('Total available', len(df))\n",
    "print('Total with rating', len(data), \"({}%)\".format(round(len(data)*100/len(df),3)))\n",
    "print('Number of sample with disagrement:', sum(~(data.rater1 == data.rater2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['skin'] = data[['rater1', 'rater2']].max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at own many \"real\" unique sample we have. Indeed a player is most certainly present multiple times. As we can see most of the players have several entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of unique player\", len(data.player.unique()))\n",
    "rows_per_player = data.player.value_counts()\n",
    "rows_per_player.hist(bins=28, range=(0, 280))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will aggregate the data to only work with a sample per player. Some of the player are present only one time and other more than one hundred time.\n",
    "\n",
    "Also a classifier as no notions of strings as input we thus need to deal with the columns with text features and encode them in a different way. We could either use a numbering encoding (clubX = 1, clubY = 2, etc) or juste dummy encode the column. We will use the dummy encoding.\n",
    "\n",
    "We also deal with the missing data (_nan_ values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill Nan values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the missing values. We will have to deal with all of them before feeding anything to the classifier. As we can see some of the column have several missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Height & Weight : Use mean\n",
    "data['height'] = data['height'].fillna(data['height'].mean())\n",
    "data['weight'] = data['weight'].fillna(data['weight'].mean())\n",
    "\n",
    "# Position: add mew label\n",
    "data['position'] = data['position'].fillna('UNKNOWN')\n",
    "\n",
    "# We decided to drop all rows containging nan in the rest of the columns. Indeed it would be difficult to \n",
    "# decide by which value we need to fill the data as they are specific for each dyad player - referee\n",
    "data.dropna(subset=['Alpha_3', 'meanIAT', 'nIAT','seIAT','meanExp','nExp','seExp'],axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to work only with information about player not dyad player-referee. We need to aggregate the unformation about each player into a single sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO Add age\n",
    "#len(data['club'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_present = lambda x: x.value_counts().index[0]\n",
    "\n",
    "players = data.groupby(level=0).agg({\n",
    "    'leagueCountry': most_present,\n",
    "    'position': most_present,\n",
    "    'club': most_present,\n",
    "    \n",
    "    'height': 'mean', \n",
    "    'weight': 'mean', \n",
    "\n",
    "    'meanIAT': most_present,\n",
    "    'meanExp':'mean', \n",
    "    #'seIAT':'mean', \n",
    "    #'seExp':'mean',\n",
    "\n",
    "    'games':'sum', \n",
    "\n",
    "    'victories':'sum',\n",
    "    'defeats':'sum', \n",
    "    'ties': 'sum', \n",
    "\n",
    "    'goals':'sum', \n",
    "\n",
    "    'redCards':'sum', \n",
    "    'yellowReds': 'sum', \n",
    "    'yellowCards':'sum',\n",
    "\n",
    "    'skin': most_present,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simplification of the task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem in all its glory is to determine the skin color within the same 5 categories. Because there is some deisagrement between raters. New \"categories\" have been created that lie in between the official ones. Let's look at the distribution of those categories. As we can see below, the categories are skewed to the right (to the \"white\" side of the categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = players['skin'].value_counts(sort=False).sort_index().plot(kind='bar')\n",
    "fig.set_ylabel('Number of players')\n",
    "fig.set_xlabel('Skin \"category\"')\n",
    "fig.set_title('Skin category by players')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to reframe the problem to a classification that decide if the playe has light skin or dark skin. Even though we will first try a simple model on the determination of the whole range of skin categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players['skin_binary'] = pd.cut(players['skin'], [0, 0.5, 1.01], labels=['light', 'dark'], right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will thus work on classifing into two category with the following distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = players['skin_binary'].value_counts(sort=False).plot(kind='bar')\n",
    "fig.set_ylabel('Number of players')\n",
    "fig.set_xlabel('Skin \"category\"')\n",
    "fig.set_title('Skin category by players')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models can not work on text features such as the position and such. We will dummy encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = players.copy()\n",
    "X.drop(['skin', 'skin_binary' ], axis=1, inplace=True)\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "y_full = players.copy()['skin']\n",
    "y = players.copy()['skin_binary']\n",
    "\n",
    "# Encoding label category\n",
    "cat_encoding = preprocessing.LabelEncoder()\n",
    "y = cat_encoding.fit_transform(y)\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(X)\n",
    "\n",
    "\n",
    "\n",
    "# Just create a struct like object\n",
    "dataset = lambda:0\n",
    "dataset.X = X\n",
    "dataset.y_full = y_full.apply(lambda x: 4*x)\n",
    "dataset.y = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our dataset into train and test. The model will be \"definied/trained\" using the train dataset and the model will be comprared on the classification based on the test set. We don't look at the test set until we do the comparision between different model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, dataset.y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will define our baseline. We start by selecting randomly the skin color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_random = np.random.randint(2, size=y_test.shape)\n",
    "print(y_random)\n",
    "print(y_test)\n",
    "\n",
    "\n",
    "metrics.f1_score(y_test, y_random, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve the score just by selecting the most present skin color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_present = mode(y_train)[0][0] # Model is definied based on train set\n",
    "y_most = np.full(y_test.shape, most_present, dtype=int)\n",
    "metrics.f1_score(y_test, y_most, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to developpe a classifier that will improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_estimators = 30\n",
    "max_depth = 20\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, max_features=None, class_weight=\"balanced\")\n",
    "scores_cross_val = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "scores_test = accuracy_score(y_test, clf.predict(X_test))\n",
    "\n",
    "print(\"Cross validation score:\", np.mean(scores_cross_val))\n",
    "print(\"Test set validation score:\", scores_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that just going straight to the goal without much thinking is not going to work. We obtain just a bit of gain compared to selecting the most present class. Let's see where we are on the overfitting side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_train, clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well... We overfit _quiet_ a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, dataset.y_full, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_random = np.random.randint(5, size=y_test.shape)\n",
    "#accuracy_score(y_test, y_random)\n",
    "metrics.f1_score(y_test, y_random, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_present = mode(y_train)[0][0] # Model is definied based on train set\n",
    "y_most = np.full(y_test.shape, most_present, dtype=int)\n",
    "metrics.f1_score(y_test, y_most, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_estimators = 35\n",
    "max_depth = 30\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=n_estimators, max_features=None, max_depth=max_depth, class_weight=\"balanced_subsample\", oob_score=True)\n",
    "scores_cross_val = cross_val_score(clf, X_train, y_train, cv=5, scoring=\"f1_weighted\")\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "scores_test = accuracy_score(y_test, predictions)\n",
    "f1_score = metrics.f1_score(y_test, predictions, average='weighted')\n",
    "print(\"Cross validation score:\", np.mean(scores_cross_val))\n",
    "print(\"Test set validation score:\", scores_test)\n",
    "print(\"F1_Score:\", f1_score)\n",
    "print(\"Training score:\", accuracy_score(y_train, clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "# Function is defined in sklearn documentation and was slightly modified to fit with our needs and the situation\n",
    "# See: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = model_selection.learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=\"f1_weighted\")\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curves (Naive Bayes)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = model_selection.ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = RandomForestClassifier()\n",
    "plot_learning_curve(estimator, title, dataset.X, dataset.y_full, ylim=(0.1, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# UTILS: use of plot_confusion_matrix\n",
    "plt.figure()\n",
    "conf_mat = metrics.confusion_matrix(y_test, predictions)\n",
    "plot_confusion_matrix(conf_mat, classes=[0,1,2,3,4], title='Confusion matrix, without normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
